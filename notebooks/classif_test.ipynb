{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src/features')))\n",
    "\n",
    "import re\n",
    "import pytz\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from process_features import preprocess_data\n",
    "from forests import ForestKind, TaskType\n",
    "from naf_model import NeuralAttentionForest, NAFParams\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path = '../../gsoc_incidents_raw3.parquet'\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "df['target'] = df['Вердикт'].apply( lambda x: True if x == 'False Positive' else (pd.NA if x == 'Не указан' else False))\n",
    "df = df[df['target'].notnull()]\n",
    "df['target'] = df['target'].astype(float)\n",
    "df = df[::1000]\n",
    "\n",
    "y = df['target'].astype(float).to_numpy()\n",
    "X = df.drop(columns=['target'])\n",
    "\n",
    "used_columns = pd.read_csv('../src/features/used_columns.csv')\n",
    "\n",
    "X = X[used_columns['column'].to_numpy()]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train = preprocess_data(X_train, '../data/transform_data_pipeline.pkl')\n",
    "\n",
    "params = NAFParams(\n",
    "    kind=ForestKind.RANDOM,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    mode='end_to_end',\n",
    "    loss='cross_entropy',\n",
    "    n_epochs=80,\n",
    "    lr=0.01,\n",
    "    lam=0.0,\n",
    "    target_loss_weight=1.0,\n",
    "    hidden_size=16,\n",
    "    gpu=True,\n",
    "    gpu_device = 3,\n",
    "    n_layers=1,\n",
    "    forest=dict(\n",
    "        n_estimators=100,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    random_state=67890\n",
    ")\n",
    "model = NeuralAttentionForest(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(params.gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "matplotlib data path: /home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "CONFIGDIR=/raid/agubarev/.config/matplotlib\n",
      "interactive is False\n",
      "platform is linux\n",
      "CACHEDIR=/raid/agubarev/.cache/matplotlib\n",
      "Using fontManager instance from /raid/agubarev/.cache/matplotlib/fontlist-v390.json\n",
      "Train E2E:   0%|          | 0/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 211, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 211, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\n                 ~~~~~~^^^^^^^\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/raid/agubarev/naf/NAF/naf_optimize_gpu/src/naf_model.py:162\u001b[39m, in \u001b[36mNeuralAttentionForest.optimize_weights\u001b[39m\u001b[34m(self, X, y_orig, batch_size, background_batch_size)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28mself\u001b[39m.device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params.mode == \u001b[33m\"\u001b[39m\u001b[33mend_to_end\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimize_weights_end_to_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_orig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params.mode == \u001b[33m\"\u001b[39m\u001b[33mtwo_step\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mself\u001b[39m._optimize_weights_two_step(X, y_orig)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/raid/agubarev/naf/NAF/naf_optimize_gpu/src/naf_model.py:351\u001b[39m, in \u001b[36mNeuralAttentionForest._optimize_weights_end_to_end\u001b[39m\u001b[34m(self, X, y_orig, batch_size, background_batch_size)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(n_epochs, desc=\u001b[33m\"\u001b[39m\u001b[33mTrain E2E\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    350\u001b[39m     epoch_losses = []\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbg_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_X_gpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackground_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbg_X\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_X_gpu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbg_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1480\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_info[idx]\n\u001b[32m   1479\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1480\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1505\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1503\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/_utils.py:733\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mRuntimeError\u001b[39m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 211, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/agubarev/miniconda3/envs/naf_work/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 211, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\n                 ~~~~~~^^^^^^^\nRuntimeError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "model.optimize_weights(X_train, y_train, batch_size=2048, background_batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(X_train.shape[1], '../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_proc = preprocess_data(X_test, '../data/transform_data_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 2/2 [00:00<00:00, 243.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max F2 = 0.550, threshold = 0.99\n"
     ]
    }
   ],
   "source": [
    "y_proba = model.predict(X_test_proc)[:, 1]\n",
    "#y_proba = model.predict(X_test_proc)\n",
    "\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "beta = 2\n",
    "\n",
    "max_f1_vals = []\n",
    "max_f1_args = []\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "y_true = np.array([1 if label == 0 else 0 for label in y_test])\n",
    "for thr in thresholds:\n",
    "    y_pred = (np.array([1 - score for score in y_proba]) >= 1 - thr).astype(int)\n",
    "    f1 = fbeta_score(y_true, y_pred, beta=beta)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "f1_scores = np.array(f1_scores)\n",
    "max_f1 = f1_scores.max()\n",
    "arg_f1 = f1_scores.argmax()\n",
    "\n",
    "print(f'max F2 = {max_f1:.3f}, threshold = {arg_f1 / 100}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naf_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
